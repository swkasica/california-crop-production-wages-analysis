{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform\n",
    "\n",
    "Ingest the raw data from the Bureau of Labor Statistics and transform it into simplified files prepared for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cpi\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set all the years of data to transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(1990, 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shortlist of industries to extract from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitelist = pd.DataFrame([\n",
    "    ('10', 'Total, all industries', 'total'),\n",
    "    ('111', 'Crop production', 'crops'),\n",
    "    ('1151', 'Support activities for crop production', 'crops'),\n",
    "], columns=['industry_code', 'industry_name', 'industry_group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where to find the CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_template = './data/{}.annual.singlefile.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area titles crosswalk to decode the raw data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_titles = pd.read_csv(\"./data/area_titles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area_fips                            object\n",
       "own_code                              int64\n",
       "industry_code                        object\n",
       "agglvl_code                           int64\n",
       "size_code                             int64\n",
       "year                                  int64\n",
       "qtr                                  object\n",
       "disclosure_code                     float64\n",
       "annual_avg_estabs                     int64\n",
       "annual_avg_emplvl                     int64\n",
       "total_annual_wages                    int64\n",
       "taxable_annual_wages                  int64\n",
       "annual_contributions                  int64\n",
       "annual_avg_wkly_wage                  int64\n",
       "avg_annual_pay                        int64\n",
       "lq_disclosure_code                   object\n",
       "lq_annual_avg_estabs                float64\n",
       "lq_annual_avg_emplvl                float64\n",
       "lq_total_annual_wages               float64\n",
       "lq_taxable_annual_wages             float64\n",
       "lq_annual_contributions             float64\n",
       "lq_annual_avg_wkly_wage             float64\n",
       "lq_avg_annual_pay                   float64\n",
       "oty_disclosure_code                  object\n",
       "oty_annual_avg_estabs_chg             int64\n",
       "oty_annual_avg_estabs_pct_chg       float64\n",
       "oty_annual_avg_emplvl_chg             int64\n",
       "oty_annual_avg_emplvl_pct_chg       float64\n",
       "oty_total_annual_wages_chg            int64\n",
       "oty_total_annual_wages_pct_chg      float64\n",
       "oty_taxable_annual_wages_chg          int64\n",
       "oty_taxable_annual_wages_pct_chg    float64\n",
       "oty_annual_contributions_chg          int64\n",
       "oty_annual_contributions_pct_chg    float64\n",
       "oty_annual_avg_wkly_wage_chg          int64\n",
       "oty_annual_avg_wkly_wage_pct_chg    float64\n",
       "oty_avg_annual_pay_chg                int64\n",
       "oty_avg_annual_pay_pct_chg          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Added by Steve\n",
    "pd.read_csv(path_template.format(years[0]), dtype={'area_fips': str}).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through all years and transform the state and county level data for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming 1990\n",
      "Transforming 1991\n",
      "Transforming 1992\n",
      "Transforming 1993\n",
      "Transforming 1994\n",
      "Transforming 1995\n",
      "Transforming 1996\n",
      "Transforming 1997\n",
      "Transforming 1998\n",
      "Transforming 1999\n",
      "Transforming 2000\n",
      "Transforming 2001\n",
      "Transforming 2002\n",
      "Transforming 2003\n",
      "Transforming 2004\n",
      "Transforming 2005\n",
      "Transforming 2006\n",
      "Transforming 2007\n",
      "Transforming 2008\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'./data/2008.annual.singlefile.csv' does not exist: b'./data/2008.annual.singlefile.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0076bdf8d4a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Read in the csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_template\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"area_fips\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Decode the area titles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'./data/2008.annual.singlefile.csv' does not exist: b'./data/2008.annual.singlefile.csv'"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    print(\"Transforming {}\".format(year))\n",
    "    \n",
    "    # Read in the csv\n",
    "    df = pd.read_csv(path_template.format(year), dtype={\"area_fips\": str})\n",
    "    \n",
    "    # Decode the area titles\n",
    "    df = df.merge(area_titles, on=\"area_fips\", how=\"inner\")\n",
    "\n",
    "    # Filter it down to desired industries using whitelist\n",
    "    filtered_df = df.merge(whitelist, on='industry_code', how=\"inner\")\n",
    "    \n",
    "    # Filter it down to the statewide aggregation level for each industry\n",
    "    state_df = filtered_df[\n",
    "        # Statewide totals for all industries\n",
    "        ((filtered_df.agglvl_code == 50) & (filtered_df.industry_group == 'total')) |\n",
    "        # Statewide totals for our selected industries\n",
    "        (\n",
    "            (filtered_df.agglvl_code.isin([55, 56])) &\n",
    "            (filtered_df.own_code == 5) &\n",
    "            (filtered_df.industry_group == 'crops')\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Filter it down to the county aggregation level for each industry\n",
    "    county_df = filtered_df[\n",
    "        # County totals for all industries\n",
    "        ((filtered_df.agglvl_code == 70) & (filtered_df.industry_group == 'total')) |\n",
    "        # County totals for our selected industries\n",
    "        (\n",
    "            (filtered_df.agglvl_code.isin([75, 76])) &\n",
    "            (filtered_df.own_code == 5) &\n",
    "            (filtered_df.industry_group == 'crops')\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Trim to only the columns we want\n",
    "    trimmed_columns = [\n",
    "        'area_fips',\n",
    "        'area_title',\n",
    "        'industry_code',\n",
    "        'industry_name',\n",
    "        'industry_group',\n",
    "        'agglvl_code',\n",
    "        'year',\n",
    "        'own_code',\n",
    "        'avg_annual_pay',\n",
    "        'annual_avg_emplvl',\n",
    "        'total_annual_wages',\n",
    "    ]\n",
    "    trimmed_state_df = state_df[trimmed_columns]\n",
    "    trimmed_county_df = county_df[trimmed_columns]\n",
    "    \n",
    "    # Adjust wages for inflation\n",
    "    trimmed_state_df['total_annual_wages_2015'] = trimmed_state_df.apply(\n",
    "        lambda x: cpi.to_2015_dollars(x.total_annual_wages, x.year),\n",
    "        axis=1\n",
    "    )\n",
    "    trimmed_county_df['total_annual_wages_2015'] = trimmed_county_df.apply(\n",
    "        lambda x: cpi.to_2015_dollars(x.total_annual_wages, x.year),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Group totals by industry group\n",
    "    groupby = [\n",
    "        'year',\n",
    "        'area_fips',\n",
    "        'area_title',\n",
    "        'industry_group'\n",
    "    ]\n",
    "    aggregation = {\n",
    "        'annual_avg_emplvl': 'sum',\n",
    "        'total_annual_wages_2015': 'sum'\n",
    "    }\n",
    "    grouped_state_df = trimmed_state_df.groupby(groupby).agg(aggregation).reset_index()\n",
    "    grouped_county_df = trimmed_county_df.groupby(groupby).agg(aggregation).reset_index()\n",
    "    \n",
    "    # Recalculate average pay for the new group\n",
    "    grouped_state_df['avg_annual_pay_2015'] = (\n",
    "        grouped_state_df.total_annual_wages_2015 / grouped_state_df.annual_avg_emplvl\n",
    "    )\n",
    "    grouped_county_df['avg_annual_pay_2015'] = (\n",
    "        grouped_county_df.total_annual_wages_2015 / grouped_county_df.annual_avg_emplvl\n",
    "    )\n",
    "    \n",
    "    # Write out each annual file separately\n",
    "    grouped_state_df.to_csv(\"./data/transformed_state_{}.csv\".format(year), index=False)\n",
    "    grouped_county_df.to_csv(\"./data/transformed_county_{}.csv\".format(year), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all the annual files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_state_df = pd.concat(\n",
    "    [pd.read_csv(\"./data/transformed_state_{}.csv\".format(year), dtype={\"area_fips\": str}) for year in years],\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_county_df = pd.concat(\n",
    "    [pd.read_csv(\"./data/transformed_county_{}.csv\".format(year), dtype={\"area_fips\": str}) for year in years],\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_state_df.to_csv(\"./data/transformed_state.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_county_df.to_csv(\"./data/transformed_county.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
